{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fff2287-659c-47fc-9d2c-97671d7fb866",
   "metadata": {},
   "source": [
    "# 線形判別モデル\n",
    "\n",
    "## モデル\n",
    "\n",
    "### 2クラスの場合\n",
    "\n",
    "2クラス$(C_1, C_2)$を識別する線形モデルを考える。\n",
    "\n",
    "特徴量ベクトルを$\\boldsymbol{x}=(x_1, \\cdots, x_d)^\\top$、係数ベクトルを$\\boldsymbol{w}=(w_1, \\cdots, w_d)^\\top$、バイアス項を$w_0$とすれば、\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) = w_0 + \\boldsymbol{w}^\\top \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "で表される。\n",
    "\n",
    "識別境界を$f(\\boldsymbol{x})=0$として、$f(\\boldsymbol{x})=0$のときはリジェクトせずに$C_1$とする場合、予測値$\\hat{C}$を出力する識別規則は\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "C_1 & (f(\\boldsymbol{x}) \\geq 0)\\\\\n",
    "C_2 & (f(\\boldsymbol{x}) < 0)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "### 多クラスの場合\n",
    "\n",
    "クラス数が$K(>2)$個ある場合にはどうすればよいだろうか。\n",
    "\n",
    "いくつか方法はある（はじパタ 6.1.2などを参照）が、最大識別関数法が現状もっとも良さそう。\n",
    "\n",
    "これは$K$個の線形識別関数$f_j(\\boldsymbol{x}) \\ (j = 1, 2, \\cdots, K)$を用意して、最も出力値が大きいクラスを採用するというもの。\n",
    "\n",
    "$$\n",
    "\\hat{C} = \\arg \\max_j f_j(\\boldsymbol{x})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f4c47-fc8f-4898-b13b-5305aa2d3b4d",
   "metadata": {},
   "source": [
    "## パラメータの推定\n",
    "\n",
    "### 最小二乗誤差基準\n",
    "\n",
    "係数ベクトルにバイアスを含めて$\\boldsymbol{w}=(w_0, w_1, \\cdots, w_d)^\\top$とし、特徴量ベクトルを$\\boldsymbol{x}=(1, x_1, \\cdots, x_d)^\\top$と表記することにする。\n",
    "\n",
    "それにより、線形識別関数を\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) = \\boldsymbol{w}^\\top \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "と表記する。\n",
    "\n",
    "教師ラベルは$\\{+1, -1\\}$で表現されるものとする。\n",
    "\n",
    "$$\n",
    "t_i = \n",
    "\\begin{cases}\n",
    "+1 & (\\boldsymbol{x}_i \\in C_1)\\\\\n",
    "-1 & (\\boldsymbol{x}_i \\in C_2)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "ここで$i$はサンプルの添字で$i = 1, \\cdots, N$である。\n",
    "\n",
    "特徴量を行列$\\boldsymbol{X} = (\\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_N)^\\top$、教師ラベルのベクトルを$\\boldsymbol{t}=(t_1, \\cdots, t_N)^\\top$と表記する。\n",
    "\n",
    "二乗誤差$E(\\boldsymbol{w})$を使って評価すると、次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(\\boldsymbol{w})\n",
    "&= \\sum^N_{i=1} (t_i - f(\\boldsymbol{x}_i))^2\\\\\n",
    "&= (\\boldsymbol{t} - \\boldsymbol{X} \\boldsymbol{w})^\\top (\\boldsymbol{t} - \\boldsymbol{X} \\boldsymbol{w})\\\\\n",
    "&= \\boldsymbol{t}\\top \\boldsymbol{t} - 2 \\boldsymbol{t}^\\top \\boldsymbol{X} \\boldsymbol{w}\n",
    " + \\boldsymbol{w}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} \\boldsymbol{w}\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d1bb8-e635-4536-a5eb-79a47468c40e",
   "metadata": {},
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70eda7-4e1d-4293-80cf-fb82e351b1f6",
   "metadata": {},
   "source": [
    "\n",
    "二乗誤差を最小にするパラメータ$\\boldsymbol{w}$は、パラメータで微分して0になるパラメータなので、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(\\boldsymbol{w})}{\\partial \\boldsymbol{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b84423-cabd-4636-a270-fe430a604075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
